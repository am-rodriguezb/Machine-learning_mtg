# Variable objetivo para clasificación (Tier -> binaria)
tier_positive_regex: "(1|2)"   # Tiers 1 o 2 = competitivo
test_size: 0.25
random_state: 42
cv_folds: 5

# modelos de clasificación y grids
cls_models:
  logreg:
    estimator: sklearn.linear_model.LogisticRegression
    params_grid:
      C: [0.1, 1, 10]
      penalty: ["l2"]
      solver: ["lbfgs"]
      max_iter: [1000]
  svm:
    estimator: sklearn.svm.SVC
    params_grid:
      C: [0.5, 1, 2]
      kernel: ["rbf", "linear"]
      gamma: ["scale", "auto"]
      probability: [true]
  rf:
    estimator: sklearn.ensemble.RandomForestClassifier
    params_grid:
      n_estimators: [200, 400]
      max_depth: [6, 10, null]
      min_samples_split: [2, 5]
  xgb:
    estimator: xgboost.XGBClassifier
    params_grid:
      n_estimators: [300, 500]
      max_depth: [4, 6]
      learning_rate: [0.05, 0.1]
      subsample: [0.8, 1.0]
      eval_metric: ["logloss"]
      random_state: [42]
  knn:
    estimator: sklearn.neighbors.KNeighborsClassifier
    params_grid:
      n_neighbors: [5, 7, 11]
      weights: ["uniform", "distance"]

# modelos de REGRESIÓN (Competitiveness Score continuo)
reg_models:
  linear_reg:
    estimator: sklearn.linear_model.LinearRegression
    params_grid: {}
  ridge:
    estimator: sklearn.linear_model.Ridge
    params_grid:
      alpha: [0.1, 1, 10, 100]
      max_iter: [1000, 2000]
  svr:
    estimator: sklearn.svm.SVR
    params_grid:
      C: [0.5, 1, 2, 10]
      kernel: ["rbf", "linear"]
      gamma: ["scale", "auto"]
      epsilon: [0.01, 0.1, 0.2]
  rf_reg:
    estimator: sklearn.ensemble.RandomForestRegressor
    params_grid:
      n_estimators: [200, 400]
      max_depth: [6, 10, null]
      min_samples_split: [2, 5]
  xgb_reg:
    estimator: xgboost.XGBRegressor
    params_grid:
      n_estimators: [300, 500]
      max_depth: [4, 6]
      learning_rate: [0.05, 0.1]
      subsample: [0.8, 1.0]
      random_state: [42]
